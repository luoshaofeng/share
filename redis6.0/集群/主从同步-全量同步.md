# Info

版本信息：Redis 6.0



# 主从同步

从库配置文件配置

```conf
replicaof <masterip> <masterport>
masterauth <master-password>
replica-read-only yes
```



## 配置加载

- 加载配置到保存到`server.masterhost`和`server.masterport`
- 将`server.repl_state`设置为`REPL_STATE_CONNECT`

```c
void loadServerConfigFromString(char *config) {
    ……

    lines = sdssplitlen(config,strlen(config),"\n",1,&totlines);

    for (i = 0; i < totlines; i++) {
      	// 配置项参数
        sds *argv;
      	// 配置项个数
        int argc;

        ……

        /* Execute config directives */
        // 有bind 配置（忽略大小写比较）
        if (!strcasecmp(argv[0],"bind") && argc >= 2) {
            ……
        } else if (!strcasecmp(argv[0],"unixsocketperm") && argc == 2) {        // 使用Unix套接字通信
            ……
        } else if ((!strcasecmp(argv[0],"slaveof") ||
                    !strcasecmp(argv[0],"replicaof")) && argc == 3) {       // 从库
            slaveof_linenum = linenum;
            sdsfree(server.masterhost);
            if (!strcasecmp(argv[1], "no") && !strcasecmp(argv[2], "one")) {
                server.masterhost = NULL;
                continue;
            }
            // 设置master节点
            server.masterhost = sdsnew(argv[1]);		// 设置masterhost为<masterip>
            char *ptr;
            // 设置端口号
            server.masterport = strtol(argv[2], &ptr, 10);	// 设置masterport为<masterport>
            if (server.masterport < 0 || server.masterport > 65535 || *ptr != '\0') {
                err = "Invalid master port"; goto loaderr;
            }
          
            // 设置要连接到主库
            server.repl_state = REPL_STATE_CONNECT;
        } else {
            err = "Bad directive or wrong number of arguments"; goto loaderr;
        }
        sdsfreesplitres(argv,argc);
    }

    ……
    return;

  	……
}
```





## 建立连接

- 从库

  从库会发起建立连接的请求。在`serverCron`函数执行，调用`replicationCron`函数

  ```c
  int serverCron(struct aeEventLoop *eventLoop, long long id, void *clientData) {
  
  		……
    
      // 主从复制
      run_with_period(1000) replicationCron();
  
      ……
  }
  ```

  `replicationCron`函数

  ```c
  void replicationCron(void) {
      ……
      // 从库操作： 连接主库
      if (server.repl_state == REPL_STATE_CONNECT) {
          serverLog(LL_NOTICE, "Connecting to MASTER %s:%d",
                    server.masterhost, server.masterport);
        
          // 连接主库
          if (connectWithMaster() == C_OK) {
              serverLog(LL_NOTICE, "MASTER <-> REPLICA sync started");
          }
      }
  
      ……
  }
  ```

  `connectWithMaster`函数

  - `server.repl_transfer_s`保存一个连接对象
  - 调用`connConnect`向主库发起建立连接请求，将文件描述符绑定到epoll（可写事件）中，连接处理函数为`syncWithMaster`
  - 更新与主库的读交互时间`server.repl_transfer_lastio`
  - 设置`server.repl_state`为`REPL_STATE_CONNECTING`

  ```c
  int connectWithMaster(void) {
      // 创建连接
      server.repl_transfer_s = server.tls_replication ? connCreateTLS() : connCreateSocket();
    
      // 建立连接，绑定到epoll中
      if (connConnect(server.repl_transfer_s, server.masterhost, server.masterport,
                      NET_FIRST_BIND_ADDR, syncWithMaster) == C_ERR) {
          serverLog(LL_WARNING, "Unable to connect to MASTER: %s",
                    connGetLastError(server.repl_transfer_s));
          connClose(server.repl_transfer_s);
          server.repl_transfer_s = NULL;
          return C_ERR;
      }
  
  
      // 更新时间和状态
      server.repl_transfer_lastio = server.unixtime;
      // 设置为已连接
      server.repl_state = REPL_STATE_CONNECTING;
      return C_OK;
  }
  ```

  之后，在主循环中检测到`fd`可写，就会触发`syncWithMaster`函数



- 主库

  建立连接后，主库就会监听从库是否有发送命令过来



## 发送ping

触发`syncWithMaster`函数后，从库会发送`ping`命令到主库

- 从库发送`ping`命令

  - 把写事件注销掉
  - 注册读事件，处理函数为`syncWithMaster`
  - 将`server.repl_state`设置为`REPL_STATE_RECEIVE_PONG`
  - 发送`ping`命令，等待主库响应，触发注册的读事件

  ```c
  void syncWithMaster(connection *conn) {
    
    	……
    
      // 发送一个ping到master节点
      if (server.repl_state == REPL_STATE_CONNECTING) {
          serverLog(LL_NOTICE, "Non blocking connect for SYNC fired the event.");
          
          // 设置连接的读处理函数
          connSetReadHandler(conn, syncWithMaster);
          connSetWriteHandler(conn, NULL);
          // 设置为接收pong
          server.repl_state = REPL_STATE_RECEIVE_PONG;
          
          // 同步发送一个ping给主库，直到超时
          err = sendSynchronousCommand(SYNC_CMD_WRITE, conn, "PING",NULL);
          if (err) goto write_error;
          return;
      }
    
    	……
  }
  ```

- 主库响应`pong`

  从库发送的`ping`请求，与普通的客户端无异，不会做特别的区分。

  `ping`请求的处理函数是`pingCommand`

  ```c
  shared.pong = createObject(OBJ_STRING, sdsnew("+PONG\r\n"));
  
  void pingCommand(client *c) {
      /* The command takes zero or one arguments. */
      if (c->argc > 2) {
          addReplyErrorFormat(c, "wrong number of arguments for '%s' command",
                              c->cmd->name);
          return;
      }
  
      if (c->flags & CLIENT_PUBSUB && c->resp == 2) {
          ……
      } else {
          if (c->argc == 1)
              addReply(c, shared.pong);		// 这里会回复"+PONG\r\n"
          ……
      }
  }
  ```

- 从库收到`pong`响应

  收到主库的响应后，调用注册的读处理函数`syncWithMaster`

  在发送`ping`命令后，`server.repl_state`被设置成了`REPL_STATE_RECEIVE_PONG`

  - 打印日志，把`server.repl_state`设置为`REPL_STATE_SEND_AUTH`

  ```c
  void syncWithMaster(connection *conn) {
    
    	……
    
      // 处理接收pong逻辑
      if (server.repl_state == REPL_STATE_RECEIVE_PONG) {
        	// 读取主库的响应
          err = sendSynchronousCommand(SYNC_CMD_READ, conn,NULL);
  
          // 异常响应
          if (err[0] != '+' &&
              strncmp(err, "-NOAUTH", 7) != 0 &&
              strncmp(err, "-NOPERM", 7) != 0 &&
              strncmp(err, "-ERR operation not permitted", 28) != 0) {
              serverLog(LL_WARNING, "Error reply to PING from master: '%s'", err);
              sdsfree(err);
              goto error;
          } else {		// 正常响应pong
              serverLog(LL_NOTICE,
                        "Master replied to PING, replication can continue...");
          }
          sdsfree(err);
          // 状态设置为发送验证
          server.repl_state = REPL_STATE_SEND_AUTH;
      }
    
    	……
  }
  ```

  

## 发送认证

这个不是必须项，如果主库需要认证的话，从库需要进行认证

- 从库认证

  发送`auth`请求到主库

  ```c
  void syncWithMaster(connection *conn) {
    
    	……
    
      // 进行认证
      if (server.repl_state == REPL_STATE_SEND_AUTH) {
        	// 用户名和密码认证
          if (server.masteruser && server.masterauth) {
              // 发送auth请求
              err = sendSynchronousCommand(SYNC_CMD_WRITE, conn, "AUTH",
                                           server.masteruser, server.masterauth,NULL);
              if (err) goto write_error;
              server.repl_state = REPL_STATE_RECEIVE_AUTH;
              return;
          } else if (server.masterauth) {		// 密码认证
              err = sendSynchronousCommand(SYNC_CMD_WRITE, conn, "AUTH", server.masterauth,NULL);
              if (err) goto write_error;
              server.repl_state = REPL_STATE_RECEIVE_AUTH;
              return;
          } else {		// 不需要的话直接发送端口号
              server.repl_state = REPL_STATE_SEND_PORT;
          }
      }
    
    	……
  }
  ```

- 主库校验密码

  校验用户名和密码

  - 如果没有用户名的话，那么就是`default`用户
  - 校验用户名和密码，成功则返回`+OK`

  ```c
  shared.ok = createObject(OBJ_STRING, sdsnew("+OK\r\n"));
  
  void authCommand(client *c) {
      /* Only two or three argument forms are allowed. */
      if (c->argc > 3) {
          addReply(c,shared.syntaxerr);
          return;
      }
  
      /* Handle the two different forms here. The form with two arguments
       * will just use "default" as username. */
      robj *username, *password;
      if (c->argc == 2) {
          /* Mimic the old behavior of giving an error for the two commands
           * from if no password is configured. */
          if (DefaultUser->flags & USER_FLAG_NOPASS) {
              addReplyError(c,"AUTH <password> called without any password "
                              "configured for the default user. Are you sure "
                              "your configuration is correct?");
              return;
          }
  
          username = createStringObject("default",7);
          password = c->argv[1];
      } else {
          username = c->argv[1];
          password = c->argv[2];
      }
  
      // 校验用户名和密码
      if (ACLAuthenticateUser(c,username,password) == C_OK) {
          addReply(c,shared.ok);
      } else {
          addReplyError(c,"-WRONGPASS invalid username-password pair");
      }
  
      /* Free the "default" string object we created for the two
       * arguments form. */
      if (c->argc == 2) decrRefCount(username);
  }
  ```

- 从库处理认证结果

  - 认证通过，则将`server.repl_state`设置为`REPL_STATE_SEND_PORT`

  ```c
  void syncWithMaster(connection *conn) {
    
    	……
    
      // 处理认证结果
      if (server.repl_state == REPL_STATE_RECEIVE_AUTH) {
          // 接收响应
          err = sendSynchronousCommand(SYNC_CMD_READ, conn,NULL);
          // 认证出错则返回错误
          if (err[0] == '-') {
              serverLog(LL_WARNING, "Unable to AUTH to MASTER: %s", err);
              sdsfree(err);
              goto error;
          }
          sdsfree(err);
          // 修改主从同步的状态
          server.repl_state = REPL_STATE_SEND_PORT;
      }
    
    	……
  }
  ```



## 发送本机监听的端口号

- 从库发送本机端口号

  - 根据配置项，向`master`节点上报本机监听的端口号，使用`REPLCONF listening-port <port>`命令
  - 将`server.repl_state`设置为`REPL_STATE_RECEIVE_PORT`

  ```c
  void syncWithMaster(connection *conn) {
    
    	……
    
      if (server.repl_state == REPL_STATE_SEND_PORT) {
          int port;
          // 配置了slave_announce_port，则端口号使用slave_announce_port
          if (server.slave_announce_port) port = server.slave_announce_port;
          else if (server.tls_replication && server.tls_port) port = server.tls_port;     // 如果是tls的话，使用tls的端口号
          else port = server.port;        // 使用常规的端口号
          sds portstr = sdsfromlonglong(port);
          // 发送REPLCONF命令，告诉master监听的接口
          err = sendSynchronousCommand(SYNC_CMD_WRITE, conn, "REPLCONF",
                                       "listening-port", portstr, NULL);
          sdsfree(portstr);
          if (err) goto write_error;
          sdsfree(err);
          // 修改状态
          server.repl_state = REPL_STATE_RECEIVE_PORT;
          return;
      }
    
    	……
  }
  ```

- 主库接收从库的端口号

  - 将上报的端口号，保存在client中

  ```c
  void replconfCommand(client *c) {
      int j;
  
      // 参数肯定是奇数
      if ((c->argc % 2) == 0) {
          /* Number of arguments must be odd to make sure that every
           * option has a corresponding value. */
          addReply(c, shared.syntaxerr);
          return;
      }
  
      for (j = 1; j < c->argc; j += 2) {
          if (!strcasecmp(c->argv[j]->ptr, "listening-port")) {   // 同步的是监听端口号
              long port;
  
              if ((getLongFromObjectOrReply(c, c->argv[j + 1],
                                            &port,NULL) != C_OK))
                  return;
              // 将上报的端口号保存在client
              c->slave_listening_port = port;
          } 
        
        	……
      }
      addReply(c, shared.ok);
  }
  ```

- 从库处理响应

  - 更新`server.repl_state`为`REPL_STATE_SEND_IP`

  ```c
  void syncWithMaster(connection *conn) {
    
    	……
    
      if (server.repl_state == REPL_STATE_RECEIVE_PORT) {
          // 读取响应值
          err = sendSynchronousCommand(SYNC_CMD_READ, conn,NULL);
          /* Ignore the error if any, not all the Redis versions support
           * REPLCONF listening-port. */
          // 不是所有版本都支持，错误的话打印一下
          if (err[0] == '-') {
              serverLog(LL_NOTICE, "(Non critical) Master does not understand "
                        "REPLCONF listening-port: %s", err);
          }
          sdsfree(err);
          // 更新状态
          server.repl_state = REPL_STATE_SEND_IP;
      }
    
    	……
  }
  ```



## 发送本机IP

- 从库发送本机IP

  - 配置了`slave_announce_ip`才需要上报，没配置的话直接跳过
  - 更新`server.repl_state`为`REPL_STATE_RECEIVE_IP`

  ```c
  void syncWithMaster(connection *conn) {
    
    	……
    
      // 没配置slave_announce_ip的话，直接跳过
      if (server.repl_state == REPL_STATE_SEND_IP &&
          server.slave_announce_ip == NULL) {
          server.repl_state = REPL_STATE_SEND_CAPA;
      }
  
      // 告诉实际的可接收ip
      if (server.repl_state == REPL_STATE_SEND_IP) {
          err = sendSynchronousCommand(SYNC_CMD_WRITE, conn, "REPLCONF",
                                       "ip-address", server.slave_announce_ip, NULL);
          if (err) goto write_error;
          sdsfree(err);
          server.repl_state = REPL_STATE_RECEIVE_IP;
          return;
      }
    
    	……
  }
  ```

- 主库处理发送的IP

  - 将从库的ip保存在client中

  ```c
  void replconfCommand(client *c) {
      int j;
  
      // 参数肯定是奇数
      if ((c->argc % 2) == 0) {
          /* Number of arguments must be odd to make sure that every
           * option has a corresponding value. */
          addReply(c, shared.syntaxerr);
          return;
      }
  
      for (j = 1; j < c->argc; j += 2) {
          if (!strcasecmp(c->argv[j]->ptr, "listening-port")) {
              ……
          } else if (!strcasecmp(c->argv[j]->ptr, "ip-address")) {
              sds ip = c->argv[j + 1]->ptr;
              if (sdslen(ip) < sizeof(c->slave_ip)) {
                  // 设置从库的IP
                  memcpy(c->slave_ip, ip, sdslen(ip) + 1);
              } else {
                  addReplyErrorFormat(c, "REPLCONF ip-address provided by "
                                      "replica instance is too long: %zd bytes", sdslen(ip));
                  return;
              }
          }
        
        	……
      }
      addReply(c, shared.ok);
  }
  ```

- 从库处理响应

  - 更新`server.repl_state`为`REPL_STATE_SEND_CAPA`

  ```c
  void syncWithMaster(connection *conn) {
    
    	……
    
      // 处理上报ip的响应值
      if (server.repl_state == REPL_STATE_RECEIVE_IP) {
          err = sendSynchronousCommand(SYNC_CMD_READ, conn,NULL);
          /* Ignore the error if any, not all the Redis versions support
           * REPLCONF listening-port. */
          if (err[0] == '-') {
              serverLog(LL_NOTICE, "(Non critical) Master does not understand "
                        "REPLCONF ip-address: %s", err);
          }
          sdsfree(err);
          // 更新状态
          server.repl_state = REPL_STATE_SEND_CAPA;
      }
    
    	……
  }
  ```



## 上报支持的同步协议

- 从库上报支持的同步协议

  - 上报支持的同步协议`eof`和`psync2`
  - 更新`server.repl_state`为`REPL_STATE_RECEIVE_CAPA`

  ```c
      // 告诉master支持的协议
      if (server.repl_state == REPL_STATE_SEND_CAPA) {
          err = sendSynchronousCommand(SYNC_CMD_WRITE, conn, "REPLCONF",
                                       "capa", "eof", "capa", "psync2",NULL);
          if (err) goto write_error;
          sdsfree(err);
          server.repl_state = REPL_STATE_RECEIVE_CAPA;
          return;
      }
  ```

- 主库处理上报的同步协议

  - 更新到client中`slave_capa`

  ```c
  void replconfCommand(client *c) {
      int j;
  
      // 参数肯定是奇数
      if ((c->argc % 2) == 0) {
          /* Number of arguments must be odd to make sure that every
           * option has a corresponding value. */
          addReply(c, shared.syntaxerr);
          return;
      }
  
      for (j = 1; j < c->argc; j += 2) {
          if (!strcasecmp(c->argv[j]->ptr, "listening-port")) {
              ……
          } else if (!strcasecmp(c->argv[j]->ptr, "ip-address")) {
              ……
          } else if (!strcasecmp(c->argv[j]->ptr, "capa")) {
              /* Ignore capabilities not understood by this master. */
              if (!strcasecmp(c->argv[j + 1]->ptr, "eof"))
                  c->slave_capa |= SLAVE_CAPA_EOF;
              else if (!strcasecmp(c->argv[j + 1]->ptr, "psync2"))
                  c->slave_capa |= SLAVE_CAPA_PSYNC2;
          }
        
        	……
      }
      addReply(c, shared.ok);
  }
  ```

- 从库处理响应

  - 更新`server.repl_state`为`REPL_STATE_SEND_PSYNC`

  ```c
  void syncWithMaster(connection *conn) {
    
    	……
    
      // 接收capa的响应
      if (server.repl_state == REPL_STATE_RECEIVE_CAPA) {
          err = sendSynchronousCommand(SYNC_CMD_READ, conn,NULL);
          if (err[0] == '-') {
              serverLog(LL_NOTICE, "(Non critical) Master does not understand "
                        "REPLCONF capa: %s", err);
          }
          sdsfree(err);
          server.repl_state = REPL_STATE_SEND_PSYNC;
      }
    
    	……
  }
  ```



## 数据同步

做完以上的操作后，就要开始同步数据了。

数据同步分成全量同步和部分同步，向master节点发送同步命令。

- 从库发送同步命令

  ```c
      // 同步数据
      if (server.repl_state == REPL_STATE_SEND_PSYNC) {
          // 发送同步命令
          if (slaveTryPartialResynchronization(conn, 0) == PSYNC_WRITE_ERROR) {
              err = sdsnew("Write error sending the PSYNC command.");
              goto write_error;
          }
          server.repl_state = REPL_STATE_RECEIVE_PSYNC;
          return;
      }
  ```

  `slaveTryPartialResynchronization`函数

  - 分成两种情况，一种是全量同步，另一种是部分同步
  - 当从库保存了主库的同步信息时，会尝试部分同步，发送`PSYNC <runid> <offset>`命令
  - 否则，全量同步，发送`PSYNC ? -1`命令
  - 发送完`PSYNC`命令后，状态会被设置为`REPL_STATE_RECEIVE_PSYNC`
  
  ```c
  int slaveTryPartialResynchronization(connection *conn, int read_reply) {
      char *psync_replid;
      char psync_offset[32];
      sds reply;
  
     // 发送同步命令
      if (!read_reply) {
          server.master_initial_offset = -1;
  
          // 有缓存了master的同步数据
          if (server.cached_master) {
              // PSYNC <runid> <offset>
              psync_replid = server.cached_master->replid;
              snprintf(psync_offset, sizeof(psync_offset), "%lld", server.cached_master->reploff + 1);
              serverLog(LL_NOTICE, "Trying a partial resynchronization (request %s:%s).", psync_replid, psync_offset);
          } else {
              // PSYNC ? -1
              serverLog(LL_NOTICE, "Partial resynchronization not possible (no cached master)");
              psync_replid = "?";
              memcpy(psync_offset, "-1", 3);
          }
  
          // 发送PSYNC命令
          reply = sendSynchronousCommand(SYNC_CMD_WRITE, conn, "PSYNC", psync_replid, psync_offset,NULL);
          if (reply != NULL) {
              serverLog(LL_WARNING, "Unable to send PSYNC to master: %s", reply);
              sdsfree(reply);
              connSetReadHandler(conn, NULL);
              return PSYNC_WRITE_ERROR;
          }
          return PSYNC_WAIT_REPLY;
      }
  
      ……
  }



- 主库处理同步命令

  当主库收到同步命令后，就会开始处理同步（分为全量同步 和 增量同步）

  



# 全量同步

## 主库

主库收到从库同步命令，可能是全量也可能是增量。如果是增量的话，主库会判断是否能够处理增量同步，不行的话会改成全量同步。

- 主库收到命令后，会尝试增量同步（判断增量同步还是全量同步）,调用`masterTryPartialResynchronization`函数
- 如果是全量同步，会设置client的属性
  - 设置同步状态
  - 表示是一个从库的客户端
- 如果没有初始化过积压复制区的话，初始化
  - 生成一个runid
  - 初始化复制积压缓冲区
- 判断当前的子进程状态
  - 如果当前正在进行rdb生成，并且是文件方式生成。那么主库会等rdb文件完全生成好，再向从库同步数据。所以
    - 如果当前从库支持的协议 与 其他等待同步的从库支持的协议一致的话，那么可以从其他从库copy同步信息（offset）
    - 如果不支持的话，由于子进程正在工作，无法生成rdb文件来同步，需要延迟从库同步操作
  - 如果当前正在进行rdb生成，但是是socket方式输出，那么需要延迟从库同步操作
  - 如果当前有活跃的子进程，那么不能进行rdb生成，延迟从库的同步操作
  - 否则，就进行全量同步

```c
// 同步请求
void syncCommand(client *c) {
    // 已经同步过 或者 monitor模式，就忽略请求
    if (c->flags & CLIENT_SLAVE) return;

    ……

    // 有需要响应给客户端的数据，出错
    if (clientHasPendingReplies(c)) {
        addReplyError(c, "SYNC and PSYNC are invalid with pending output");
        return;
    }

    // 打印日志
    serverLog(LL_NOTICE, "Replica %s asks for synchronization",
              replicationGetSlaveName(c));

    // 如果是psync命令
    if (!strcasecmp(c->argv[0]->ptr, "psync")) {
        // 尝试部分同步
        if (masterTryPartialResynchronization(c) == C_OK) {
            server.stat_sync_partial_ok++;
            return;
        } else {        // 无法部分同步，只能全量同步
            char *master_replid = c->argv[1]->ptr;      // 记录同步的runid

            if (master_replid[0] != '?') server.stat_sync_partial_err++;
        }
    } else {        // sync命令
        c->flags |= CLIENT_PRE_PSYNC;
    }

    server.stat_sync_full++;

    // 设置同步状态
    c->replstate = SLAVE_STATE_WAIT_BGSAVE_START;
    // 设置conn的属性（不延迟）
    if (server.repl_disable_tcp_nodelay)
        connDisableTcpNoDelay(c->conn);
    c->repldbfd = -1;
    // 标识这是一个从库的客户端
    c->flags |= CLIENT_SLAVE;
    // 添加客户端到从库列表中
    listAddNodeTail(server.slaves, c);

    // 初始化 复制积压数据
    if (listLength(server.slaves) == 1 && server.repl_backlog == NULL) {
        // 设置一个runid
        changeReplicationId();
        // 清掉replid2
        clearReplicationId2();
        // 积压缓冲区初始化
        createReplicationBacklog();
        serverLog(LL_NOTICE, "Replication backlog created, my new "
                  "replication IDs are '%s' and '%s'",
                  server.replid, server.replid2);
    }

    // 当前正在进行 rdb文件的生成
    if (server.rdb_child_pid != -1 &&
        server.rdb_child_type == RDB_CHILD_TYPE_DISK) {
        client *slave;
        listNode *ln;
        listIter li;

        // 遍历从库
        listRewind(server.slaves, &li);
        // 找到一个等待bgsave结束的从库client
        while ((ln = listNext(&li))) {
            slave = ln->value;
            if (slave->replstate == SLAVE_STATE_WAIT_BGSAVE_END) break;
        }
      
        // 当前客户端支持的同步协议 和 其他从库支持的同步协议是否一致
        if (ln && ((c->slave_capa & slave->slave_capa) == slave->slave_capa)) {
            // 支持的协议是一致的
            // 复制slave的响应给当前客户端
            copyClientOutputBuffer(c, slave);
            // 响应客户端全量同步 +FULLRESYNC runid offset
            replicationSetupSlaveForFullResync(c, slave->psync_initial_offset);
            serverLog(LL_NOTICE, "Waiting for end of BGSAVE for SYNC");
        } else {        // 等待下一次bgsave
            serverLog(LL_NOTICE, "Can't attach the replica to the current BGSAVE. Waiting for next BGSAVE for SYNC");
        }

        /* CASE 2: BGSAVE is in progress, with socket target. */
        // 正在通过socket写入rdb，等待下一次bgsave
    } else if (server.rdb_child_pid != -1 &&
               server.rdb_child_type == RDB_CHILD_TYPE_SOCKET) {
        serverLog(LL_NOTICE, "Current BGSAVE has socket target. Waiting for next BGSAVE for SYNC");

        // 没有bgsave请求
    } else {
        if (server.repl_diskless_sync && (c->slave_capa & SLAVE_CAPA_EOF)) {
            if (server.repl_diskless_sync_delay)
                serverLog(LL_NOTICE, "Delay next BGSAVE for diskless SYNC");
        } else {
            // 没有活跃的子进程
            if (!hasActiveChildProcess()) {
                // 开始给从库执行bgsave
                startBgsaveForReplication(c->slave_capa);
            } else {        // 有其他活跃的后台子进程，delay
                serverLog(LL_NOTICE,
                          "No BGSAVE in progress, but another BG operation is active. "
                          "BGSAVE for replication delayed");
            }
        }
    }
    return;
}
```

### 尝试增量同步

主库收到命令后，会尝试增量同步（判断增量同步还是全量同步）,调用`masterTryPartialResynchronization`函数

进行全量同步的情况有两种：

- 从库发送的runid 与 主库的不相同，进行全量同步
- runid相等，但是从库要同步的offset 不在 积压复制缓冲区的范围内

```c
int masterTryPartialResynchronization(client *c) {
    long long psync_offset, psync_len;
    char *master_replid = c->argv[1]->ptr;      // runid
    char buf[128];
    int buflen;

    // 解析出offset
    if (getLongLongFromObjectOrReply(c, c->argv[2], &psync_offset,NULL) !=
        C_OK)
        goto need_full_resync;

    // runid 不相等，进行全量同步
    if (strcasecmp(master_replid, server.replid) &&
        (strcasecmp(master_replid, server.replid2) ||
         psync_offset > server.second_replid_offset)) {
        
        // 不等于？，说明想要从库执行的操作是部分同步
        if (master_replid[0] != '?') {      // 没办法执行部分同步
            if (strcasecmp(master_replid, server.replid) &&
                strcasecmp(master_replid, server.replid2)) {
                serverLog(LL_NOTICE, "Partial resynchronization not accepted: "
                          "Replication ID mismatch (Replica asked for '%s', my "
                          "replication IDs are '%s' and '%s')",
                          master_replid, server.replid, server.replid2);
            } else {
                serverLog(LL_NOTICE, "Partial resynchronization not accepted: "
                          "Requested offset for second ID was %lld, but I can reply "
                          "up to %lld", psync_offset, server.second_replid_offset);
            }
        } else {        // 从库想要执行的是全量同步
            serverLog(LL_NOTICE, "Full resync requested by replica %s",
                      replicationGetSlaveName(c));
        }
        goto need_full_resync;
    }

    // 没有积压缓冲区 或者 要同步的偏移量小于积压缓冲区的起始偏移量 或者 要同步的偏移量比整个积压缓冲区的偏移量还大
    // 那么无法进行增量同步，改为全量同步
    if (!server.repl_backlog ||
        psync_offset < server.repl_backlog_off ||
        psync_offset > (server.repl_backlog_off + server.repl_backlog_histlen)) {
        serverLog(LL_NOTICE,
                  "Unable to partial resync with replica %s for lack of backlog (Replica request was: %lld).",
                  replicationGetSlaveName(c), psync_offset);
        if (psync_offset > server.master_repl_offset) {
            serverLog(LL_WARNING,
                      "Warning: replica %s tried to PSYNC with an offset that is greater than the master replication offset.",
                      replicationGetSlaveName(c));
        }
        goto need_full_resync;
    }

    ……

need_full_resync:
    return C_ERR;
}
```



### RDB全量同步

 如果当前没有子进程在工作，并且主库配置的是有盘同步 或者 从库不支持无盘同步（也就是主库现在要进行有盘同步），那么会立马调用`startBgsaveForReplication`进行同步。

这个函数本身是支持两种同步方式的：无盘同步（socket同步）和有盘同步（文件同步）

- 先构造一个rdbSaveInfo，rdb文件保存的一些信息，增量同步会用到
- 判断主库当前要用无盘同步还是有盘同步
  - 有盘同步：调用`rdbSaveBackground`处理
  - 无盘同步：调用`rdbSaveToSlavesSockets`处理
- 如果是有盘同步，更新从库client的同步状态，响应每个客户端

```c
int startBgsaveForReplication(int mincapa) {
    int retval;
    // 无盘同步方式
    int socket_target = server.repl_diskless_sync && (mincapa & SLAVE_CAPA_EOF);
    listIter li;
    listNode *ln;

    serverLog(LL_NOTICE, "Starting BGSAVE for SYNC with target: %s",
              socket_target ? "replicas sockets" : "disk");

    rdbSaveInfo rsi, *rsiptr;
    // 构造rsi
    rsiptr = rdbPopulateSaveInfo(&rsi);
    if (rsiptr) {
        if (socket_target)
            retval = rdbSaveToSlavesSockets(rsiptr);                        // 子进程写rdb socket
        else
            retval = rdbSaveBackground(server.rdb_filename, rsiptr);        // 子进程写rdb文件
    } else {
        serverLog(
            LL_WARNING,
            "BGSAVE for replication: replication information not available, can't generate the RDB file right now. Try later.");
        retval = C_ERR;
    }

    ……

    // 文件传输，子进程已经开始了，响应客户端
    if (!socket_target) {
        listRewind(server.slaves, &li);
        while ((ln = listNext(&li))) {
            client *slave = ln->value;

            if (slave->replstate == SLAVE_STATE_WAIT_BGSAVE_START) {
                // 响应客户端
                replicationSetupSlaveForFullResync(slave,
                                                   getPsyncInitialOffset());
            }
        }
    }

    // 重置资源
    if (retval == C_OK) replicationScriptCacheFlush();
    return retval;
}
```

#### 无盘同步

- 无盘同步`rdbSaveToSlavesSockets`

  - 创建一对管道，作用是：子进程生成rdb文件后，通过该管道把数据传给主进程，主进程再把数据同步给从库
    - 子进程用的是写管道，阻塞的，子进程写完后，会把写管道关闭，通知主进程已经写完RDB文件
    - 主进程用的是读管道，非阻塞的，会注册到epoll中，设置读处理函数，处理函数为`rdbPipeReadHandler`
  - 创建另一对管道，作用是：
    - 主进程用的是写管道，阻塞的，用于主进程通知子进程，已经完成所有从库的同步，可以安全退出了
    - 子进程用的是读管道，阻塞的，等待主进程完成同步，随后安全退出进程

  - 拿出所有从库待开始状态（`SLAVE_STATE_WAIT_BGSAVE_START`）的连接，设置为待结束状态`SLAVE_STATE_WAIT_BGSAVE_END`，记录偏移量，并响应客户端全量同步（`+FULLRESYNC runid offset`）
  - 开始fork子进程，处理rdb数据的生成并同步，调用`rdbSaveRioWithEOFMark`函数，把rdb文件通过管道写入，让主进程同步给从库

  ```c
  int rdbSaveToSlavesSockets(rdbSaveInfo *rsi) {
      listNode *ln;
      listIter li;
      pid_t childpid;
      int pipefds[2], rdb_pipe_write, safe_to_exit_pipe;
  
      ……
      
      // 创建一对管道
      if (pipe(pipefds) == -1) return C_ERR;
      server.rdb_pipe_read = pipefds[0]; /* read end */
      rdb_pipe_write = pipefds[1]; /* write end */
      anetNonBlock(NULL, server.rdb_pipe_read);
  
      // 创建另一对管道
      if (pipe(pipefds) == -1) {
          close(rdb_pipe_write);
          close(server.rdb_pipe_read);
          return C_ERR;
      }
      safe_to_exit_pipe = pipefds[0]; /* read end */
      server.rdb_child_exit_pipe = pipefds[1]; /* write end */
  
      // 所有从库的conn
      server.rdb_pipe_conns = zmalloc(sizeof(connection *)*listLength(server.slaves));
      server.rdb_pipe_numconns = 0;
      server.rdb_pipe_numconns_writing = 0;
      listRewind(server.slaves,&li);
      while((ln = listNext(&li))) {
          client *slave = ln->value;
          if (slave->replstate == SLAVE_STATE_WAIT_BGSAVE_START) {
              // 保存从库的连接
              server.rdb_pipe_conns[server.rdb_pipe_numconns++] = slave->conn;
              // 响应全量同步
              replicationSetupSlaveForFullResync(slave,getPsyncInitialOffset());
          }
      }
  
      /* Create the child process. */
      // 创建子进程信息管道
      openChildInfoPipe();
      // 创建子进程
      if ((childpid = redisFork(CHILD_TYPE_RDB)) == 0) {
          /* Child */
          int retval, dummy;
          rio rdb;
  
          // 初始化rdb（rdb_pipe_write 阻塞写）
          rioInitWithFd(&rdb,rdb_pipe_write);
  
          // 设置进程相关属性
          redisSetProcTitle("redis-rdb-to-slaves");
          redisSetCpuAffinity(server.bgsave_cpulist);
  
          // 整个rdb数据通过socket写到子进程
          retval = rdbSaveRioWithEOFMark(&rdb,NULL,rsi);
          // 刷出去
          if (retval == C_OK && rioFlush(&rdb) == 0)
              retval = C_ERR;
  
          // 报告子进程的信息
          if (retval == C_OK) {
              sendChildCOWInfo(CHILD_TYPE_RDB, "RDB");
          }
  
          // 释放资源
          rioFreeFd(&rdb);
          close(rdb_pipe_write);
          close(server.rdb_child_exit_pipe)
          dummy = read(safe_to_exit_pipe, pipefds, 1);
          UNUSED(dummy);
          // 退出进程
          exitFromChild((retval == C_OK) ? 0 : 1);
      } else {
          /* Parent */
          close(safe_to_exit_pipe);
          // 异常
          if (childpid == -1) {
              ……
          } else {
              serverLog(LL_NOTICE,"Background RDB transfer started by pid %d",
                  childpid);
              server.rdb_save_time_start = time(NULL);
              server.rdb_child_pid = childpid;
              server.rdb_child_type = RDB_CHILD_TYPE_SOCKET;
              // 更新为尽量避免重哈希
              updateDictResizePolicy();
              close(rdb_pipe_write);
              // 注册epoll节点，可读事件，处理函数为 rdbPipeReadHandler
              if (aeCreateFileEvent(server.el, server.rdb_pipe_read, AE_READABLE, rdbPipeReadHandler,NULL) == AE_ERR) {
                  serverPanic("Unrecoverable error creating server.rdb_pipe_read file event.");
              }
          }
          return (childpid == -1) ? C_ERR : C_OK;
      }
      return C_OK; /* Unreached. */
  }
  ```

  - 子进程同步rdb内容，调用`rdbSaveRioWithEOFMark`

    - 首先会以`$EOF:`为开头，随后写入40个字节（随机字符串），用来从库标识当前全量同步已经结束
    - 之后写入整个数据库的rdb数据，这个过程与rdb持久化是完全一致的。只不过一个写入的fd是文件，这个是管道
    - 最后写入结束标识，告诉从库，全量同步已经结束
    - 整个过程是同步过程

    ```c
    int rdbSaveRioWithEOFMark(rio *rdb, int *error, rdbSaveInfo *rsi) {
        char eofmark[RDB_EOF_MARK_SIZE];
    
        startSaving(RDBFLAGS_REPLICATION);
        // 取随机字符作为传输的末尾
        getRandomHexChars(eofmark,RDB_EOF_MARK_SIZE);
        if (error) *error = 0;
        // 开头
        if (rioWrite(rdb,"$EOF:",5) == 0) goto werr;
        // 结束标识
        if (rioWrite(rdb,eofmark,RDB_EOF_MARK_SIZE) == 0) goto werr;
        // 换行
        if (rioWrite(rdb,"\r\n",2) == 0) goto werr;
        // 开始写整个rdb数据
        if (rdbSaveRio(rdb,error,RDBFLAGS_NONE,rsi) == C_ERR) goto werr;
        // 写完写结束标识
        if (rioWrite(rdb,eofmark,RDB_EOF_MARK_SIZE) == 0) goto werr;
        stopSaving(1);
        return C_OK;
    
    werr:
        if (error && *error == 0) *error = errno;
        stopSaving(0);
        return C_ERR;
    }
    ```

  - 同步处理函数`rdbPipeReadHandler`，

    - 从管道从读取子进程发送的数据
    - 拿出所有待同步的从库，把数据发送到从库中。看看本次获取的读取能不能完全的写给从库
      - 如果某个从库只写入了部分数据，注销读事件，注册写事件（退出循环）。当数据全部同步给从库后，才会继续注册读事件，处理后续的数据
      - 如果全部写完给所有从库，不断循环处理上述过程，直到子进程暂时没有数据发送过来，退出循环，等待下一次读事件触发
    - 读取到写管道关闭，从库全量同步已经完成，注销读事件，完成全量同步

    ```c
    void rdbPipeReadHandler(struct aeEventLoop *eventLoop, int fd, void *clientData, int mask) {
        UNUSED(mask);
        UNUSED(clientData);
        UNUSED(eventLoop);
        int i;
        // 初始化一个io缓冲区
        if (!server.rdb_pipe_buff)
            server.rdb_pipe_buff = zmalloc(PROTO_IOBUF_LEN);
        serverAssert(server.rdb_pipe_numconns_writing==0);
    
        while (1) {
            // 管道管道读取数据
            server.rdb_pipe_bufflen = read(fd, server.rdb_pipe_buff, PROTO_IOBUF_LEN);
            // 出错
            if (server.rdb_pipe_bufflen < 0) {
              	// 暂时读取不到数据导致的err，返回
                if (errno == EAGAIN || errno == EWOULDBLOCK)
                    return;
                ……
            }
    
            // 写端关闭了，文件写完了
            if (server.rdb_pipe_bufflen == 0) {
                int stillUp = 0;
                aeDeleteFileEvent(server.el, server.rdb_pipe_read, AE_READABLE);
                for (i = 0; i < server.rdb_pipe_numconns; i++) {
                    connection *conn = server.rdb_pipe_conns[i];
                    if (!conn)
                        continue;
                    stillUp++;
                }
                serverLog(LL_WARNING, "Diskless rdb transfer, done reading from pipe, %d replicas still up.", stillUp);
              
                // 通知子进程安全退出
                close(server.rdb_child_exit_pipe);
                // 设置为-1
                server.rdb_child_exit_pipe = -1;
                return;
            }
    
            int stillAlive = 0;
            for (i = 0; i < server.rdb_pipe_numconns; i++) {
                int nwritten;
                connection *conn = server.rdb_pipe_conns[i];
                if (!conn)
                    continue;
    
                client *slave = connGetPrivateData(conn);
                // 发送同步数据给从库
                if ((nwritten = connWrite(conn, server.rdb_pipe_buff, server.rdb_pipe_bufflen)) == -1) {
                    ……
                } else {
                    // 更新偏移量
                    slave->repldboff = nwritten;
                    server.stat_net_output_bytes += nwritten;
                }
              
                // 数据没有全部发送出去
                if (nwritten != server.rdb_pipe_bufflen) {
                    slave->repl_last_partial_write = server.unixtime;
                    server.rdb_pipe_numconns_writing++;
                    // 注册写函数
                    connSetWriteHandler(conn, rdbPipeWriteHandler);
                }
                stillAlive++;
            }
    
            // 没有要同步的从库了，杀掉RDB子进程进程
            if (stillAlive == 0) {
                serverLog(LL_WARNING, "Diskless rdb transfer, last replica dropped, killing fork child.");
                killRDBChild();
            }
            // 注册了写事件的话，就把读事件删掉，防止缓冲区被覆盖
            if (server.rdb_pipe_numconns_writing || stillAlive == 0) {
                aeDeleteFileEvent(server.el, server.rdb_pipe_read, AE_READABLE);
                break;
            }
        }
    }
    ```



#### 有盘同步

- 有盘同步`rdbSaveBackground`

  有盘同步与rdb持久化是完成一致的，生成一个rdb文件，生成完文件之后，才会同步给从库

  这里并没有更新client的同步状态，所以才会在外层函数去更新，并且响应客户端

  

### 监控子进程退出

#### 无盘同步

无盘同步，监控到子进程退出时，已经完成了从库数据的同步

最终会调用`backgroundSaveDoneHandlerSocket`函数来处理进程退出

```c
int serverCron(struct aeEventLoop *eventLoop, long long id, void *clientData) {
  
  	……
  
    // 检查子进程是否已完成
    if (hasActiveChildProcess() || ldbPendingChildren()) {
        checkChildrenDone();
    } else {
        ……
    }
  
    ……
}


void checkChildrenDone(void) {
    int statloc;
    pid_t pid;

    // 检查是否有子进程退出，获取子进程ID
    if ((pid = wait3(&statloc,WNOHANG,NULL)) != 0) {
        // 获取退出码
        int exitcode = WEXITSTATUS(statloc);
        int bysignal = 0;

        // 子进程是否是被杀死的
        if (WIFSIGNALED(statloc)) bysignal = WTERMSIG(statloc);     // 取出杀死它的信号编码

        // 主进程杀死的
        if (exitcode == SERVER_CHILD_NOERROR_RETVAL) {
            bysignal = SIGUSR1;     // 标记成"被我自己杀的"
            exitcode = 1;           // 伪装成普通的失败退出（防止误报成功）
        }

        if (pid == -1) {
            ……
        } else if (pid == server.rdb_child_pid) {       // 处理rdb子进程退出
            backgroundSaveDoneHandler(exitcode, bysignal);
            if (!bysignal && exitcode == 0) receiveChildInfo();
        }
      
      	……
    }
}


void backgroundSaveDoneHandler(int exitcode, int bysignal) {
    int type = server.rdb_child_type;
    switch(server.rdb_child_type) {
    case RDB_CHILD_TYPE_DISK:        // 本地持久化
        ……
    case RDB_CHILD_TYPE_SOCKET:     // 主从同步，rdb通过socket传输
        backgroundSaveDoneHandlerSocket(exitcode,bysignal);
        break;
    default:
        serverPanic("Unknown RDB child type.");
        break;
    }

    server.rdb_child_pid = -1;
    server.rdb_child_type = RDB_CHILD_TYPE_NONE;
    server.rdb_save_time_last = time(NULL)-server.rdb_save_time_start;
    server.rdb_save_time_start = -1;
    
    // 更新待执行的从库client状态
    updateSlavesWaitingBgsave((!bysignal && exitcode == 0) ? C_OK : C_ERR, type);
}
```



`backgroundSaveDoneHandlerSocket`函数

监控到进程退出后，重置同步过程中用到的资源

```c
static void backgroundSaveDoneHandlerSocket(int exitcode, int bysignal) {
    if (!bysignal && exitcode == 0) {
        serverLog(LL_NOTICE,
            "Background RDB transfer terminated with success");
    } else if (!bysignal && exitcode != 0) {
        serverLog(LL_WARNING, "Background transfer error");
    } else {
        serverLog(LL_WARNING,
            "Background transfer terminated by signal %d", bysignal);
    }
    // 重置资源
    if (server.rdb_child_exit_pipe!=-1)
        close(server.rdb_child_exit_pipe);
    aeDeleteFileEvent(server.el, server.rdb_pipe_read, AE_READABLE);
    close(server.rdb_pipe_read);
    server.rdb_child_exit_pipe = -1;
    server.rdb_pipe_read = -1;
    zfree(server.rdb_pipe_conns);
    server.rdb_pipe_conns = NULL;
    server.rdb_pipe_numconns = 0;
    server.rdb_pipe_numconns_writing = 0;
    zfree(server.rdb_pipe_buff);
    server.rdb_pipe_buff = NULL;
    server.rdb_pipe_bufflen = 0;
}
```



- 更新待同步（待开始、待结束）执行的从库状态`updateSlavesWaitingBgsave`

  - 遍历所有从库的client，如果是等待同步结束(`SLAVE_STATE_WAIT_BGSAVE_END`)的client，更新为在线(`SLAVE_STATE_ONLINE`)
  - 如果有待同步(`SLAVE_STATE_WAIT_BGSAVE_START`)的client，开始全量同步

  ```c
  void updateSlavesWaitingBgsave(int bgsaveerr, int type) {
      listNode *ln;
      int startbgsave = 0;
      int mincapa = -1;
      listIter li;
  
  
      listRewind(server.slaves, &li);
      // 遍历所有从库的客户端
      while ((ln = listNext(&li))) {
          client *slave = ln->value;
  
          // 如果是待开始同步的从库，统计所有从库都支持的协议
          if (slave->replstate == SLAVE_STATE_WAIT_BGSAVE_START) {
              startbgsave = 1;
              mincapa = (mincapa == -1) ? slave->slave_capa : (mincapa & slave->slave_capa);
          } else if (slave->replstate == SLAVE_STATE_WAIT_BGSAVE_END) {       // 如果是已经完成同步的从库
              struct redis_stat buf;
  
              ……
  
              // 如果是无盘同步方式
              if (type == RDB_CHILD_TYPE_SOCKET) {
                  serverLog(LL_NOTICE,
                            "Streamed RDB transfer with replica %s succeeded (socket). Waiting for REPLCONF ACK from slave to enable streaming",
                            replicationGetSlaveName(slave));
                  
                  slave->replstate = SLAVE_STATE_ONLINE;      // 将状态更新为在线
                  slave->repl_put_online_on_ack = 1;
                  slave->repl_ack_time = server.unixtime; /* Timeout otherwise. */
              } else {        // 如果是有盘同步方式，数据还没发送给从库
                  ……
              }
          }
      }
    
    	// 全量同步
      if (startbgsave) startBgsaveForReplication(mincapa);
  }





#### 有盘同步

直接从`backgroundSaveDoneHandler`函数看，有盘同步与持久化是一致的

- 更新主库的dirty数
- 记录一次执行的时间
- 记录最后一次执行的结果
- 更新待同步（待开始、待结束）执行的从库状态

```c
void backgroundSaveDoneHandler(int exitcode, int bysignal) {
    int type = server.rdb_child_type;
    switch(server.rdb_child_type) {
    case RDB_CHILD_TYPE_DISK:        // 本地持久化
        backgroundSaveDoneHandlerDisk(exitcode,bysignal);
        break;
    case RDB_CHILD_TYPE_SOCKET:     // 主从同步，rdb通过socket传输
        ……
    default:
        serverPanic("Unknown RDB child type.");
        break;
    }

    server.rdb_child_pid = -1;
    server.rdb_child_type = RDB_CHILD_TYPE_NONE;
    server.rdb_save_time_last = time(NULL)-server.rdb_save_time_start;
    server.rdb_save_time_start = -1;

    // 更新待同步（待开始、待结束）执行的从库状态
    updateSlavesWaitingBgsave((!bysignal && exitcode == 0) ? C_OK : C_ERR, type);
}


static void backgroundSaveDoneHandlerDisk(int exitcode, int bysignal) {
    if (!bysignal && exitcode == 0) {
        serverLog(LL_NOTICE,
            "Background saving terminated with success");
        // 更新主库目前的dirty数（触发rdb持久化）
        server.dirty = server.dirty - server.dirty_before_bgsave;
        server.lastsave = time(NULL);
        server.lastbgsave_status = C_OK;
    } else if (!bysignal && exitcode != 0) {
        ……
    } else {
        ……
    }
}
```



- 更新待同步（待开始、待结束）执行的从库状态`updateSlavesWaitingBgsave`

  有盘同步，目前只是生成了一个持久化文件，还没有同步数据给从库

  - 遍历所有从库的client，如果是等待同步结束(`SLAVE_STATE_WAIT_BGSAVE_END`)的client
    - 打开刚持久化的rdb文件
    - 记录文件的大小
    - 更新从库的同步状态为`SLAVE_STATE_SEND_BULK`批量发送
    - 注册写事件，写处理函数为`sendBulkToSlave`，在socket可写的时候会触发调用
  - 如果有待同步(`SLAVE_STATE_WAIT_BGSAVE_START`)的client，开始全量同步

  ```c
  void updateSlavesWaitingBgsave(int bgsaveerr, int type) {
      listNode *ln;
      int startbgsave = 0;
      int mincapa = -1;
      listIter li;
  
  
      listRewind(server.slaves, &li);
      // 遍历所有从库的客户端
      while ((ln = listNext(&li))) {
          client *slave = ln->value;
  
          // 如果是待开始同步的从库，统计所有从库都支持的协议
          if (slave->replstate == SLAVE_STATE_WAIT_BGSAVE_START) {
              startbgsave = 1;
              mincapa = (mincapa == -1) ? slave->slave_capa : (mincapa & slave->slave_capa);
          } else if (slave->replstate == SLAVE_STATE_WAIT_BGSAVE_END) {       // 如果是已经完成同步的从库
              struct redis_stat buf;
  
              if (bgsaveerr != C_OK) {
                  freeClientAsync(slave);
                  serverLog(LL_WARNING, "SYNC failed. BGSAVE child returned an error");
                  continue;
              }
  
              // 如果是无盘同步方式
              if (type == RDB_CHILD_TYPE_SOCKET) {
                  ……
              } else {        // 如果是有盘同步方式，数据还没发送给从库
                  // 打开生成好的rdb文件
                  if ((slave->repldbfd = open(server.rdb_filename,O_RDONLY)) == -1 ||
                      redis_fstat(slave->repldbfd, &buf) == -1) {
                      freeClientAsync(slave);
                      serverLog(LL_WARNING, "SYNC failed. Can't open/stat DB after BGSAVE: %s", strerror(errno));
                      continue;
                  }
                  slave->repldboff = 0;
                  slave->repldbsize = buf.st_size;
                  // 设置状态为批量发送
                  slave->replstate = SLAVE_STATE_SEND_BULK;
                  slave->replpreamble = sdscatprintf(sdsempty(), "$%lld\r\n",
                                                     (unsigned long long) slave->repldbsize);
  
                  connSetWriteHandler(slave->conn,NULL);
                  // 注册写事件，处理函数为 sendBulkToSlave
                  if (connSetWriteHandler(slave->conn, sendBulkToSlave) == C_ERR) {
                      freeClientAsync(slave);
                      continue;
                  }
              }
          }
      }
    
      if (startbgsave) startBgsaveForReplication(mincapa);
  }



- 写处理函数`sendBulkToSlave`

  - 写文件头`$<length>\r\n`
  - 从rdb文件读取数据，把rdb文件的内容发给客户端
  - 如果整个文件写完了，注销写事件
  - 更新每个从库的状态为在线

  ```c
  void sendBulkToSlave(connection *conn) {
      client *slave = connGetPrivateData(conn);
      char buf[PROTO_IOBUF_LEN];
      ssize_t nwritten, buflen;
  
      if (slave->replpreamble) {
          // 写文件头$<length>\r\n
          nwritten = connWrite(conn, slave->replpreamble, sdslen(slave->replpreamble));
          if (nwritten == -1) {
              serverLog(LL_VERBOSE,
                        "Write error sending RDB preamble to replica: %s",
                        connGetLastError(conn));
              freeClient(slave);
              return;
          }
          server.stat_net_output_bytes += nwritten;
          sdsrange(slave->replpreamble, nwritten, -1);
          // 文件头全部写入，继续写
          if (sdslen(slave->replpreamble) == 0) {
              sdsfree(slave->replpreamble);
              slave->replpreamble = NULL;
              /* fall through sending data. */
          } else {        // 如果没有全部写入成功，先退出。等待下一次写事件触发
              return;
          }
      }
  
      /* If the preamble was already transferred, send the RDB bulk data. */
      // 设置读取位置
      lseek(slave->repldbfd, slave->repldboff,SEEK_SET);
      // 从文件读取数据
      buflen = read(slave->repldbfd, buf,PROTO_IOBUF_LEN);
      if (buflen <= 0) {
          serverLog(LL_WARNING, "Read error sending DB to replica: %s",
                    (buflen == 0) ? "premature EOF" : strerror(errno));
          freeClient(slave);
          return;
      }
      // 将读取的数据通过socket发送到从库
      if ((nwritten = connWrite(conn, buf, buflen)) == -1) {
          if (connGetState(conn) != CONN_STATE_CONNECTED) {
              serverLog(LL_WARNING, "Write error sending DB to replica: %s",
                        connGetLastError(conn));
              freeClient(slave);
          }
          return;
      }
      // 更新偏移量
      slave->repldboff += nwritten;
      server.stat_net_output_bytes += nwritten;
      // 整个文件完成写入
      if (slave->repldboff == slave->repldbsize) {
          close(slave->repldbfd);
          slave->repldbfd = -1;
          // 注销写处理函数
          connSetWriteHandler(slave->conn,NULL);
          // 设置从库在线
          putSlaveOnline(slave);
      }
  }





## 从库

### 处理响应值

从库发送`PSYNC`命令后，同步状态会被设置为`REPL_STATE_RECEIVE_PSYNC`，然后就等待主库响应，触发读事件，继续调用`syncWithMaster`函数

然后再次调用`slaveTryPartialResynchronization`函数，执行后面一部分的逻辑（之前调用只执行了一半的逻辑）

- 调用`slaveTryPartialResynchronization`拿到master的响应值，判断是全量同步还是增量同步
- 全量同步，调用`disconnectSlaves`进行全量同步
- 从库有两种方式接收：无盘同步和有盘同步
  - 无盘同步：接收到命令后立即写入数据库
  - 有盘同步：先写入rdb文件，之后再加载到数据库
- 如果是有盘同步的，打开文件，保存文件描述符
- 注册读事件，接收主从发送的同步数据，处理函数为`connSetReadHandler`
- 之后状态会被设置为`REPL_STATE_TRANSFER`

```c
void syncWithMaster(connection *conn) {
    
  	……
    
    if (server.repl_state != REPL_STATE_RECEIVE_PSYNC) {
        serverLog(LL_WARNING, "syncWithMaster(): state machine error, "
                  "state should be RECEIVE_PSYNC but is %d",
                  server.repl_state);
        goto error;
    }

    psync_result = slaveTryPartialResynchronization(conn, 1);
    if (psync_result == PSYNC_WAIT_REPLY) return;

    if (psync_result == PSYNC_TRY_LATER) goto error;


    if (psync_result == PSYNC_CONTINUE) {
        ……
        return;
    }

    ……

    // 开始进行全量同步

    // 不使用无盘加载
    if (!useDisklessLoad()) {
        // 打开临时文件
        while (maxtries--) {
            snprintf(tmpfile, 256,
                     "temp-%d.%ld.rdb", (int) server.unixtime, (long int) getpid());
            dfd = open(tmpfile,O_CREAT | O_WRONLY | O_EXCL, 0644);
            if (dfd != -1) break;
            sleep(1);
        }
        if (dfd == -1) {
            serverLog(LL_WARNING, "Opening the temp file needed for MASTER <-> REPLICA synchronization: %s",
                      strerror(errno));
            goto error;
        }
        // 保存临时文件
        server.repl_transfer_tmpfile = zstrdup(tmpfile);
        // 临时文件描述符
        server.repl_transfer_fd = dfd;
    }


    // 设置主从同步处理函数
    if (connSetReadHandler(conn, readSyncBulkPayload)
        == C_ERR) {
        char conninfo[CONN_INFO_LEN];
        serverLog(LL_WARNING,
                  "Can't create readable event for SYNC: %s (%s)",
                  strerror(errno), connGetInfo(conn, conninfo, sizeof(conninfo)));
        goto error;
    }

    server.repl_state = REPL_STATE_TRANSFER;
    server.repl_transfer_size = -1;
    server.repl_transfer_read = 0;
    server.repl_transfer_last_fsync_off = 0;
    server.repl_transfer_lastio = server.unixtime;
    return;

		……
}
```

- `slaveTryPartialResynchronization`函数

  - 解析主从的runid和offset，保存到`server.master_replid`和`server.master_initial_offset`

  ```c
  int slaveTryPartialResynchronization(connection *conn, int read_reply) {
    
      ……
        
      // 读取主库的响应值
      reply = sendSynchronousCommand(SYNC_CMD_READ, conn,NULL);
      if (sdslen(reply) == 0) {
          sdsfree(reply);
          return PSYNC_WAIT_REPLY;
      }
  
      // 注销读事件
      connSetReadHandler(conn, NULL);
  
      // 全同步 +FULLRESYNC <runid> <offset>
      if (!strncmp(reply, "+FULLRESYNC", 11)) {
          char *replid = NULL, *offset = NULL;
  
          replid = strchr(reply, ' ');
          if (replid) {
              // 拿到runid的值
              replid++;
              offset = strchr(replid, ' ');
              // 拿到offset的值
              if (offset) offset++;
          }
          // 校验返回的格式是否正确
          if (!replid || !offset || (offset - replid - 1) != CONFIG_RUN_ID_SIZE) {
              serverLog(LL_WARNING,
              memset(server.master_replid, 0,CONFIG_RUN_ID_SIZE + 1);
          } else {
              // 解析master回复的runid
              memcpy(server.master_replid, replid, offset - replid - 1);
              server.master_replid[CONFIG_RUN_ID_SIZE] = '\0';
              // 解析偏移量
              server.master_initial_offset = strtoll(offset,NULL, 10);
              serverLog(LL_NOTICE, "Full resync from master: %s:%lld",
                        server.master_replid,
                        server.master_initial_offset);
          }
          // 要做全量同步，去掉增量同步相关的缓存
          replicationDiscardCachedMaster();
          sdsfree(reply);
          return PSYNC_FULLRESYNC;
      }
  
      ……
                        
  }
  ```



### 接收主库的同步数据

读事件处理函数`readSyncBulkPayload`处理主库发送的同步数据

- 判断主库使用的是有盘同步还是无盘同步
  - 有盘同步：记录文件的大小
  - 无盘同步：记录文件结束标识符，用于判断同步结束

```c
void readSyncBulkPayload(connection *conn) {
    char buf[PROTO_IOBUF_LEN];
    ssize_t nread, readlen, nwritten;
    int use_diskless_load = useDisklessLoad(); // 是否使用无盘加载
    dbBackup *diskless_load_backup = NULL;
    // 清空策略
    int empty_db_flags = server.repl_slave_lazy_flush ? EMPTYDB_ASYNC : EMPTYDB_NO_FLAGS;
    off_t left;

    // static：函数退出，下次调用函数，数据还在
    static char eofmark[CONFIG_RUN_ID_SIZE];
    static char lastbytes[CONFIG_RUN_ID_SIZE];
    // 主库的同步协议
    static int usemark = 0;

    // 刚开始同步，解析头部
    if (server.repl_transfer_size == -1) {
        if (connSyncReadLine(conn, buf, 1024, server.repl_syncio_timeout * 1000) == -1) {
            serverLog(LL_WARNING,
                      "I/O error reading bulk count from MASTER: %s",
                      strerror(errno));
            goto error;
        }

        if (buf[0] == '-') {
            // master同步出错
            serverLog(LL_WARNING,
                      "MASTER aborted replication with an error: %s",
                      buf + 1);
            goto error;
        } else if (buf[0] == '\0') {
            /* At this stage just a newline works as a PING in order to take
             * the connection live. So we refresh our last interaction
             * timestamp. */
            // 刷新交互时间
            server.repl_transfer_lastio = server.unixtime;
            return;
        } else if (buf[0] != '$') {
            // 同步协议不对
            serverLog(
                LL_WARNING,
                "Bad protocol from MASTER, the first byte is not '$' (we received '%s'), are you sure the host and port are right?",
                buf);
            goto error;
        }

        // 读取文件头
        // 主库使用无盘同步
        if (strncmp(buf + 1, "EOF:", 4) == 0 && strlen(buf + 5) >= CONFIG_RUN_ID_SIZE) {
            usemark = 1;
            // 保存结束标识
            memcpy(eofmark, buf + 5,CONFIG_RUN_ID_SIZE);
            // 将lastbytes都设置为0
            memset(lastbytes, 0,CONFIG_RUN_ID_SIZE);
            /* Set any repl_transfer_size to avoid entering this code path
             * at the next call. */
            server.repl_transfer_size = 0;
            serverLog(LL_NOTICE,
                      "MASTER <-> REPLICA sync: receiving streamed RDB from master with EOF %s",
                      use_diskless_load ? "to parser" : "to disk");
        } else {        // 主库使用有盘同步
            usemark = 0;
          	// 记录整个文件的大小
            server.repl_transfer_size = strtol(buf + 1,NULL, 10);
            serverLog(LL_NOTICE,
                      "MASTER <-> REPLICA sync: receiving %lld bytes from master %s",
                      (long long) server.repl_transfer_size,
                      use_diskless_load ? "to parser" : "to disk");
        }
        return;
    }
}
```



### 有盘同步

- 从库使用的是有盘同步，根据主库使用的是有盘同步还是无盘同步，解析整个文件数据，写入到磁盘中
- 对于主库的有盘同步：只需要根据文件的大小，读取固定的字节数就可以了
- 否则：根据文件头给的结束标识，进行对比，判断文件结束
- 文件读取完之后立即刷盘
- 进入数据写到缓存流程，与无盘同步差不多

```c
void readSyncBulkPayload(connection *conn) {
  
  	……
  
    // 刚开始同步，解析头部
    if (server.repl_transfer_size == -1) {
        ……
    }
  
    // 从库使用有盘同步，把整个数据写到磁盘，之后才进行后面的流程
    if (!use_diskless_load) {
        if (usemark) {      // 主库使用的是无盘同步
            readlen = sizeof(buf);
        } else {            // 主库使用的是有盘同步
            // 读取的字节数
            left = server.repl_transfer_size - server.repl_transfer_read;
            readlen = (left < (signed) sizeof(buf)) ? left : (signed) sizeof(buf);
        }

        // 从socket中读取
        nread = connRead(conn, buf, readlen);
        if (nread <= 0) {
            if (connGetState(conn) == CONN_STATE_CONNECTED) {
                return;
            }
            serverLog(LL_WARNING, "I/O error trying to sync with MASTER: %s",
                      (nread == -1) ? strerror(errno) : "connection lost");
            cancelReplicationHandshake();
            return;
        }
        server.stat_net_input_bytes += nread;

        int eof_reached = 0;

        if (usemark) {      // 使用的是无盘同步，校验结束标识
            // 设置最后CONFIG_RUN_ID_SIZE个字节到 lastbytes
            if (nread >= CONFIG_RUN_ID_SIZE) {
                memcpy(lastbytes, buf + nread - CONFIG_RUN_ID_SIZE,
                       CONFIG_RUN_ID_SIZE);
            } else {
                int rem = CONFIG_RUN_ID_SIZE - nread;
                memmove(lastbytes, lastbytes + nread, rem);
                memcpy(lastbytes + rem, buf, nread);
            }
            if (memcmp(lastbytes, eofmark,CONFIG_RUN_ID_SIZE) == 0)     // 最后40个字节跟eofmark对上了，无盘同步（主库）结束
                eof_reached = 1;
        }

        server.repl_transfer_lastio = server.unixtime;
        // 写入rdb临时文件
        if ((nwritten = write(server.repl_transfer_fd, buf, nread)) != nread) {
            serverLog(LL_WARNING,
                      "Write error or short write writing to the DB dump file "
                      "needed for MASTER <-> REPLICA synchronization: %s",
                      (nwritten == -1) ? strerror(errno) : "short write");
            goto error;
        }
        server.repl_transfer_read += nread;

        // 截断最后40个字节
        if (usemark && eof_reached) {
            if (ftruncate(server.repl_transfer_fd,
                          server.repl_transfer_read - CONFIG_RUN_ID_SIZE) == -1) {
                serverLog(LL_WARNING,
                          "Error truncating the RDB file received from the master "
                          "for SYNC: %s", strerror(errno));
                goto error;
            }
        }

        // 刷盘
        if (server.repl_transfer_read >=
            server.repl_transfer_last_fsync_off + REPL_MAX_WRITTEN_BEFORE_FSYNC) {
            off_t sync_size = server.repl_transfer_read -
                              server.repl_transfer_last_fsync_off;
            rdb_fsync_range(server.repl_transfer_fd,
                            server.repl_transfer_last_fsync_off, sync_size);
            server.repl_transfer_last_fsync_off += sync_size;
        }

        // 校验是否已经完全读取完了
        if (!usemark) {
            if (server.repl_transfer_read == server.repl_transfer_size)
                eof_reached = 1;
        }

        // 没同步完就退出,等待写完整个文件再处理，因为这是有盘模式
        if (!eof_reached) return;
    }
}
```



#### 加载数据

- 清除从库原先的数据（根据策略来选择是同步删除还是异步删除）
- 注销读事件

- 将临时文件重命名为rdb持久化文件名
- 加载整个rdb文件，写到数据库中

```c
void readSyncBulkPayload(connection *conn) {
  
  	……
  
    // 清除旧数据库
    emptyDb(-1, empty_db_flags, replicationEmptyDbCallback);

    connSetReadHandler(conn, NULL);
      
    if (use_diskless_load) {        // 本地使用无盘加载
        ……
    } else {        // 使用有盘同步
        // 如果有rdb线程，杀掉
        if (server.rdb_child_pid != -1) {
            ……
        }

        // 刷盘
        if (fsync(server.repl_transfer_fd) == -1) {
            ……
        }

        int old_rdb_fd = open(server.rdb_filename,O_RDONLY | O_NONBLOCK);
        // 替换rdb文件
        if (rename(server.repl_transfer_tmpfile, server.rdb_filename) == -1) {
            serverLog(LL_WARNING,
                      "Failed trying to rename the temp DB into %s in "
                      "MASTER <-> REPLICA synchronization: %s",
                      server.rdb_filename, strerror(errno));
            cancelReplicationHandshake();
            if (old_rdb_fd != -1) close(old_rdb_fd);
            return;
        }
        /* Close old rdb asynchronously. */
        // 后台线程关闭旧文件（触发页回写的话可能会慢）
        if (old_rdb_fd != -1) bioCreateBackgroundJob(BIO_CLOSE_FILE, (void *) (long) old_rdb_fd,NULL,NULL);

        // 通过文件加载整个rdb文件
        if (rdbLoad(server.rdb_filename, &rsi,RDBFLAGS_REPLICATION) != C_OK) {
            serverLog(LL_WARNING,
                      "Failed trying to load the MASTER synchronization "
                      "DB from disk");
            cancelReplicationHandshake();
            if (server.rdb_del_sync_files && allPersistenceDisabled()) {
                serverLog(LL_NOTICE, "Removing the RDB file obtained from "
                          "the master. This replica has persistence "
                          "disabled");
                bg_unlink(server.rdb_filename);
            }
            return;
        }

        // 删除同步的文件
        if (server.rdb_del_sync_files && allPersistenceDisabled()) {
            serverLog(LL_NOTICE, "Removing the RDB file obtained from "
                      "the master. This replica has persistence "
                      "disabled");
            bg_unlink(server.rdb_filename);
        }

        // 释放资源
        zfree(server.repl_transfer_tmpfile);
        close(server.repl_transfer_fd);
        server.repl_transfer_fd = -1;
        server.repl_transfer_tmpfile = NULL;
    }
  
  	……
  
}
```







### 无盘同步

- 清除从库原先的数据（根据策略来选择是同步删除还是异步删除）
- 注销读事件
- 将文件描述符设置为阻塞模式，与rdb文件加载到数据库一样，从socket把数据加载到数据库

```c
void readSyncBulkPayload(connection *conn) {
  
  	……
      
    // 清除旧数据库
    emptyDb(-1, empty_db_flags, replicationEmptyDbCallback);

    connSetReadHandler(conn, NULL);
  
    if (use_diskless_load) {        // 本地使用无盘加载
        rio rdb;
        rioInitWithConn(&rdb, conn, server.repl_transfer_size);

        // 设置阻塞模式
        connBlock(conn);
        connRecvTimeout(conn, server.repl_timeout * 1000);
        startLoading(server.repl_transfer_size, RDBFLAGS_REPLICATION);

        // 在网络中把整个rdb文件读取过来
        if (rdbLoadRio(&rdb,RDBFLAGS_REPLICATION, &rsi) != C_OK) {
            ……
            return;
        }
        stopLoading(1);

        if (server.repl_diskless_load == REPL_DISKLESS_LOAD_SWAPDB) {
            // 删除备用库
            disklessLoadDiscardBackup(diskless_load_backup, empty_db_flags);
        }

        // 校验文件尾是否正确
        if (usemark) {      // 主库使用的是无盘模式
            if (!rioRead(&rdb, buf,CONFIG_RUN_ID_SIZE) ||
                memcmp(buf, eofmark,CONFIG_RUN_ID_SIZE) != 0) {
                serverLog(LL_WARNING, "Replication stream EOF marker is broken");
                cancelReplicationHandshake();
                rioFreeConn(&rdb, NULL);
                return;
            }
        }

        // 处理完成，释放资源
        rioFreeConn(&rdb, NULL);
        connNonBlock(conn);
        connRecvTimeout(conn, 0);
    }
  
  	……
}
```



### 从主库设置为从库的客户端

- 将主库的连接封装成客户端，保存在`server.master`中
- 记录该客户端的同步信息`server.master->replid`，`server.master->reploff`，`server.master->read_reploff`
- 标识这是一个主库的客户端`server.master->flags |= CLIENT_MASTER;`
- 设置同步状态为`REPL_STATE_CONNECTED`已连接
- 设置当前从库的同步信息`server.replid`，`server.master_repl_offset`
- 初始化复制积压缓冲区

```c
void readSyncBulkPayload(connection *conn) {
    ……

    // 设置当前从库的客户端（主库）
    replicationCreateMasterClient(server.repl_transfer_s, rsi.repl_stream_db);
    server.repl_state = REPL_STATE_CONNECTED;
    server.repl_down_since = 0;

    ……

    memcpy(server.replid, server.master->replid, sizeof(server.replid));
    server.master_repl_offset = server.master->reploff;
    clearReplicationId2();

    if (server.repl_backlog == NULL) createReplicationBacklog();
  
    ……
    return;

error:
    cancelReplicationHandshake();
    return;
}


// 设置主库和从库的连接（模拟客户端->服务器，这里是主库->从库）
void replicationCreateMasterClient(connection *conn, int dbid) {
    server.master = createClient(conn);
    if (conn)
        connSetReadHandler(server.master->conn, readQueryFromClient);
    // 设置这个客户端是主库
    server.master->flags |= CLIENT_MASTER;
    server.master->authenticated = 1;
    // 设置主从同步的信息
    server.master->reploff = server.master_initial_offset;
    server.master->read_reploff = server.master->reploff;
    server.master->user = NULL; /* This client can do everything. */
    memcpy(server.master->replid, server.master_replid,
           sizeof(server.master_replid));
    /* If master offset is set to -1, this master is old and is not
     * PSYNC capable, so we flag it accordingly. */
    if (server.master->reploff == -1)
        server.master->flags |= CLIENT_PRE_PSYNC;
    // 主库目前选择的db
    if (dbid != -1) selectDb(server.master, dbid);
}
```

整个全量同步过程结束，之后便由主库主动同步命令到从库。



# 同步期间的增量命令

增量期间的命令会保存在client的响应中等待发送给客户端，但是不会发送到客户端去，只有等到完全同步完（从库上线后），才会把增量命令同步给客户端

- 传播命令
  - 客户端请求最终会调用call来执行，执行完命令后会传播这个命令

```c
void call(client *c, int flags) {
    ……

    /* Propagate the command into the AOF and replication link */
    // 传播这个命令
    if (flags & CMD_CALL_PROPAGATE &&
        (c->flags & CLIENT_PREVENT_PROP) != CLIENT_PREVENT_PROP) {
        ……
        // 传播命令
        if (propagate_flags != PROPAGATE_NONE && !(c->cmd->flags & CMD_MODULE))
            propagate(c->cmd, c->db->id, c->argv, c->argc, propagate_flags);
    }

    ……
}

void propagate(struct redisCommand *cmd, int dbid, robj **argv, int argc,
               int flags) {
    ……
    // 传播给从库
    if (flags & PROPAGATE_REPL)
        replicationFeedSlaves(server.slaves, dbid, argv, argc);
}
```

- 传播命令到从库

  - 将命令保存到复制积压缓冲区
  - 将命令放入到从库的client中，待响应给客户端（全量同步期间不会写回客户端，先缓存起来）

  ```c
  void replicationFeedSlaves(list *slaves, int dictid, robj **argv, int argc) {
      listNode *ln;
      listIter li;
      int j, len;
      char llstr[LONG_STR_SIZE];
  
      // 这是一个从库，不需要传播消息到从库
      if (server.masterhost != NULL) return;
  
      // 没有从库，并且没有积压缓冲区
      if (server.repl_backlog == NULL && listLength(slaves) == 0) return;
  
      // 当前选中的数据库 与 最后一次同步选中的数据库不一致
      if (server.slaveseldb != dictid) {
          robj *selectcmd;
  
          // 构建一个选中数据库的请求
          if (dictid >= 0 && dictid < PROTO_SHARED_SELECT_CMDS) {
              selectcmd = shared.select[dictid];
          } else {
              int dictid_len;
  
              dictid_len = ll2string(llstr, sizeof(llstr), dictid);
              selectcmd = createObject(OBJ_STRING,
                                       sdscatprintf(sdsempty(),
                                                    "*2\r\n$6\r\nSELECT\r\n$%d\r\n%s\r\n",
                                                    dictid_len, llstr));
          }
  
          // 如果有积压复制缓冲区，写入
          if (server.repl_backlog) feedReplicationBacklogWithObject(selectcmd);
  
          listRewind(slaves, &li);
          while ((ln = listNext(&li))) {
              client *slave = ln->value;
              // 如果从库是等待开始同步，不同步
              if (slave->replstate == SLAVE_STATE_WAIT_BGSAVE_START) continue;
              // 否则，添加响应到客户端待响应buffer中
              addReply(slave, selectcmd);
          }
  
          if (dictid < 0 || dictid >= PROTO_SHARED_SELECT_CMDS)
              decrRefCount(selectcmd);
      }
      // 最后一次同步到客户端的数据库id
      server.slaveseldb = dictid;
  
      // 将此次请求写入到复制积压缓冲区中
      if (server.repl_backlog) {
          char aux[LONG_STR_SIZE + 3];
  
          aux[0] = '*';
          len = ll2string(aux + 1, sizeof(aux) - 1, argc);
          aux[len + 1] = '\r';
          aux[len + 2] = '\n';
          feedReplicationBacklog(aux, len + 3);
  
          for (j = 0; j < argc; j++) {
              long objlen = stringObjectLen(argv[j]);
              aux[0] = '$';
              len = ll2string(aux + 1, sizeof(aux) - 1, objlen);
              aux[len + 1] = '\r';
              aux[len + 2] = '\n';
              feedReplicationBacklog(aux, len + 3);
              feedReplicationBacklogWithObject(argv[j]);
              feedReplicationBacklog(aux + len + 1, 2);
          }
      }
  
      listRewind(slaves, &li);
      // 将请求同步给从库(放到待响应队列中)
      while ((ln = listNext(&li))) {
          client *slave = ln->value;
  
          if (slave->replstate == SLAVE_STATE_WAIT_BGSAVE_START) continue;
  
          addReplyArrayLen(slave, argc);
  
          for (j = 0; j < argc; j++)
              addReplyBulk(slave, argv[j]);
      }
  }
  ```

- 全量同步期间不响应客户端

  - 只有当`c->replstate == SLAVE_STATE_ONLINE && !c->repl_put_online_on_ack`时，客户端才会被添加到`server.clients_pending_write`，才会响应客户端。所以在全量同步期间，客户端不会收到增量命令。等待全量同步完成之后，才会继续把增量命令同步给客户端。之后主库同步给从库的数据也是通过这里来传播

  ```c
  // 添加响应
  void addReply(client *c, robj *obj) {
      // 准备写入数据
      if (prepareClientToWrite(c) != C_OK) return;
  
      // 响应都是string类型的
      if (sdsEncodedObject(obj)) {
          // buf不能添加，添加到队列中
          if (_addReplyToBuffer(c, obj->ptr, sdslen(obj->ptr)) != C_OK)
              // 添加到队列
              _addReplyProtoToList(c, obj->ptr, sdslen(obj->ptr));
      } else if (obj->encoding == OBJ_ENCODING_INT) {
          char buf[32];
          size_t len = ll2string(buf, sizeof(buf), (long) obj->ptr);
          if (_addReplyToBuffer(c, buf, len) != C_OK)
              _addReplyProtoToList(c, buf, len);
      } else {
          serverPanic("Wrong obj->encoding in addReply()");
      }
  }
  
  
  int prepareClientToWrite(client *c) {
      ……
      
      //客户端缓冲区没有待处理数据写入，客户端也不是准备读
      if (!clientHasPendingReplies(c) && !(c->flags & CLIENT_PENDING_READ))
          clientInstallWriteHandler(c);       // slave状态为SLAVE_STATE_WAIT_BGSAVE_END时，这里并不会添加到响应队列里面去，也就不会去响应客户端，会一直积攒着增量命令
      return C_OK;
  }
  
  
  void clientInstallWriteHandler(client *c) {
      if (!(c->flags & CLIENT_PENDING_WRITE) &&
          (c->replstate == REPL_STATE_NONE ||
           (c->replstate == SLAVE_STATE_ONLINE && !c->repl_put_online_on_ack))) {     // 状态为SLAVE_STATE_WAIT_BGSAVE_END时，不会添加到响应队列去，也就不会去响应客户端
          c->flags |= CLIENT_PENDING_WRITE; //设置为数据待写入
          listAddNodeHead(server.clients_pending_write, c);
      }
  }
  ```



到此，整个增量同步的流程就走完了

